---
title: 'Brazilian Senate Speeches'
output: 
  html_document: 
    toc: yes
    theme: paper
    toc_float:
      collapsed: no
    df_print: kable
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggrepel)
library(ggplot2)
library(tidyverse)
library(tidytext)
library(quanteda)
library(quanteda.textmodels)
library(stm)
```

# Ideas

* How parties position themselves in senate speeches x party manifesto -- Wordfish comparison.

# Data

## Senate

```{r}
# Load speeches data frame
load('data/speech_df.Rda')

# Corpus
corp_sen <- corpus(speech_df, docid_field = 'CodigoPronunciamento', 
                     text_field = 'Pronunciamento')

# DFM
dfmat_sen <- dfm(corp_sen,
  tolower = TRUE,
  remove_punct = TRUE,
  remove = stopwords('portuguese'),
  remove_numbers = TRUE,
  remove_separators = TRUE,
  remove_symbols = TRUE,
  stem = FALSE,  
  groups = 'Partido')


# Additional stopwords
stopwords1 <- c('presidente', 'exa', 'excelencia', 'senhor', 'aqui', 'porque', 'ser',
                'então', 'quero', 'vai', 'ainda', 'ter', 'pode', 'bem', 'obrigado',
                'assim', 'dessa', 'srs', 'cada', 'portanto', 'outro', 'toda', 'além', 
                'nesse', 'nesta', 'desta', 'deste', 'disso', 'sra', 'pois', 'nó', 'sr',
                'aí', 'senador', 'senadores')


# Remove additional stopwords
dfmat_sen <- dfm_remove(dfmat_sen, stopwords1)

# Set minumum number of characters
dfmat_sen <- dfm_select(dfmat_sen, min_nchar = 2)

# Keep only words occurring in at most 9/10 of the documents
## acho que não precisa já que a análise vai ser de palavras usadas pelos dois lados. + se usarmos essa função, a palavra 'deus' sai da dfm. ##
#dfmat_sen <- dfm_trim(dfmat_sen, max_docfreq = 0.95, docfreq_type = 'prop')

# Name documents
docnames(dfmat_sen) <- paste(dfmat_sen$Partido)
```

## Executive

```{r}
# Corpus
load('data/corp_exec.Rda')

corp_exec %>% 
  tokens() %>% 
  tokens_remove(stopwords("portuguese")) %>% 
  textstat_collocations(method = "lambda", size = 2) %>% 
  arrange(-lambda) %>%  
  top_n(20)

# DFM
dfmat_exec <- dfm(corp_exec,
  tolower = TRUE,
  remove_punct = TRUE,
  remove = stopwords('portuguese'),
  remove_numbers = TRUE,
  remove_separators = TRUE,
  remove_symbols = TRUE,
  stem = FALSE)


# Additional stopwords
stopwords1 <- c('presidente', 'exa', 'excelencia', 'senhor', 'aqui', 'porque', 'ser',
                'então', 'quero', 'vai', 'ainda', 'ter', 'pode', 'bem', 'obrigado',
                'assim', 'dessa', 'srs', 'cada', 'portanto', 'outro', 'toda', 'além', 
                'nesse', 'nesta', 'desta', 'deste', 'disso', 'sra', 'pois', 'nó', 'sr',
                'aí', 'senador', 'senadores')


# Remove additional stopwords
dfmat_exec <- dfm_remove(dfmat_exec, stopwords1)

# Set minumum number of characters
dfmat_exec <- dfm_select(dfmat_exec, min_nchar = 2)
```


# Wordfish

## Senate 

```{r}
# Print doc 20
dfmat_sen[20, 1] # PT

# Print doc 11
dfmat_sen[11, 1] # PR

# Wordfish model
wf_sen <- textmodel_wordfish(dfmat_sen, dir = c(20, 11), sparse = TRUE)
textplot_scale1d(wf_sen)
```


## Executive

```{r}
# Print doc 3
dfmat_exec[3, 1] # bolsonaro

# Print doc 11
dfmat_exec[4, 1] # boulos

# Wordfish model
wf_exec <- textmodel_wordfish(dfmat_exec, dir = c(4, 3), sparse = TRUE)
textplot_scale1d(wf_exec)
```