---
title: "R Notebook"
output: html_notebook
---
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(plyr)
library(readr)
library(quanteda)
library(readtext)
```

# Senate

Download senators data frame. 

```{r}
senators <- sen_senator_list()
```

Loop to download 17527 individual speeches from senators that will form the larger corpus

```{r}
for(i in 1:80) { try({
  endpoint <- glue(paste0("https://legis.senado.leg.br/dadosabertos/senador/",   senators$id[i], "/discursos"))
  
  raw_json <- GET(endpoint, add_headers("Accept:application/json"))
  parsed_json <- fromJSON(content(raw_json, "text"), flatten = TRUE)
  str(parsed_json)
  speech_df <- parsed_json$DiscursosParlamentar$Parlamentar$Pronunciamentos$Pronunciamento
  
  url_list <-
    as.list(as.data.frame(t(speech_df['UrlTextoBinario'])))
  
  names_list <- 
    as.list(as.data.frame(t(speech_df['CodigoPronunciamento'])))  
  
  names <- 
    tidyr::expand_grid(names_list) %>%
    glue_data("{names_list}.rtf")
  
  safe_download <- safely(~ download.file(.x , .y, mode = "wb"))
  walk2(url_list, names, safe_download)}, silent=FALSE)}
```


Download senator tables from https://www12.senado.leg.br/dados-abertos and create data frame. 

```{r}
# Create empty data frame
sen_df <- data.frame()

# Download senator data frame and bind to `sen_df`
for (i in 1:80) {
  try({
  endpoint <- glue(paste0("https://legis.senado.leg.br/dadosabertos/senador/",    senators$id[i], "/discursos"))
  
  raw_json <- GET(endpoint, add_headers("Accept:application/json"))
  parsed_json <- fromJSON(content(raw_json, "text"), flatten = TRUE)
  str(parsed_json)
  
  df <- parsed_json$DiscursosParlamentar$Parlamentar$Pronunciamentos$Pronunciamento
  
  df <- df %>% 
    dplyr::select(CodigoPronunciamento, DataPronunciamento, SiglaPartidoParlamentarNaData,                    UfParlamentarNaData, SessaoPlenaria.NumeroSessao)
  
  df$Id <- paste(senators$id[i])
  
  df$Nome <- paste(senators$name_senator[i])
  
  sen_df <- rbind(sen_df,df)
  }, silent = FALSE)}
  

# Reorder columns
sen_df <- sen_df[c(6, 7, 1, 2, 3, 4, 5)]

# Save
save(sen_df,file = "sen_df.Rda")
```

Create data frame with senators speeches. 

```{r}
# Create Path
pdf_path <- "C:\\Users\\carol\\Desktop\\Fall_2020\\TADA\\Senado\\Web"

# List PDFs 
pdfs <- list.files(path = pdf_path, pattern = "*.pdf", full.names = TRUE) 

# Create data frame
speech_df <- readtext(pdfs,
                        docvarsfrom = "filenames", verbosity = TRUE)

# Rename and select relevant columns
speech_df <- speech_df %>% 
  dplyr::rename(CodigoPronunciamento = docvar1, Pronunciamento = text) %>% 
  select(CodigoPronunciamento, Pronunciamento)

# Save
save(speech_df, file = "speech_df.Rda")
```


Merge the two data frames and remove empty rows. Here we go from 17544 observations to 15588 because 1956 of the speech files downloaded were empty. 

```{r}
# Merge `sen_df` and `speech_df` and omit empty rows
sen_corpus_df <- merge(sen_df, speech_df, by = "CodigoPronunciamento") %>% 
  na_if("") %>%
  na.omit 

# Save corpus data frame
save(speech_df, file = "speech_df.Rda")
```

# Executive

Import government programs for the 2018 presidential election.

```{r}
pdf_path <- "C:\\Users\\carol\\Desktop\\Fall_2020\\Python\\github_python\\tada\\data\\pres_prog"

# List PDF
pdfs <- list.files(path = pdf_path, pattern = "*.pdf", full.names = TRUE) 

# Import PDF
spill_texts <- readtext(pdfs,
                        docvarsfrom = "filenames", verbosity = TRUE)

```

Add party variable and coalitions

```{r}
pres_df <- spill_texts %>% 
  select(id = docvar1, text) 

parties <- readr::read_delim("pres_prog/parties.csv", 
    ";", escape_double = FALSE, trim_ws = TRUE)

pres_df <- merge(pres_df, parties, by = 'id')
save(pres_df, file = 'pres_df.Rda')
```

